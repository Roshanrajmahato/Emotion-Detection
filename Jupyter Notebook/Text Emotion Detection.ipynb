{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "358d7d7d",
   "metadata": {},
   "source": [
    "# TEXT EMOTION DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616dbc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7ea18",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fdf46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"emotion_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4841dd0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b224913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55053732",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Emotion',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e44cdbf",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1175202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neattext.functions as nfx\n",
    "\n",
    "# Remove the user handles\n",
    "df['Clean_Text'] = df['Text'].apply(nfx.remove_userhandles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bff967",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(nfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b8f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the stopwords\n",
    "df['Clean_Text'] = df['Clean_Text'].apply(nfx.remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdaf676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a61757d",
   "metadata": {},
   "source": [
    "### Splitting data into input variables and target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b12855",
   "metadata": {},
   "source": [
    "x: Features are the attributes and variables extracted from the dataset. These extracted features are used as inputs to the model during training.\n",
    "\n",
    "y: Labels are the output or the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2568bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Clean_Text']\n",
    "y = df['Emotion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be53a4f",
   "metadata": {},
   "source": [
    "### Splitting data into train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153c41a",
   "metadata": {},
   "source": [
    "We need to split our dataset into a train set and test set. The model will learn from the train set. We will use the test set to evaluate the model performance and measure the modelâ€™s knowledge capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94068470",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab70dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3bb4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline(steps=[('cv',CountVectorizer()),('lr',LogisticRegression())])\n",
    "pipe_lr.fit(x_train,y_train)\n",
    "pipe_lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svm = Pipeline(steps=[('cv',CountVectorizer()),('svc', SVC(kernel = 'rbf', C = 10))])\n",
    "pipe_svm.fit(x_train,y_train)\n",
    "pipe_svm.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e9ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline(steps=[('cv',CountVectorizer()),('rf', RandomForestClassifier(n_estimators=10))])\n",
    "pipe_rf.fit(x_train,y_train)\n",
    "pipe_rf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac497a",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed05d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "pipeline_file = open(\"text_emotion.pkl\",\"wb\")\n",
    "joblib.dump(pipe_lr,pipeline_file)\n",
    "pipeline_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a21ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
